{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer,TfidfTransformer\n",
    "import jieba\n",
    "import numpy as np\n",
    "train_first = pd.read_csv('E:\\\\data mining\\\\dataset\\\\Reputation-evaluation-of-scenic-spots\\\\chusai\\\\train_first.csv')\n",
    "train_second = pd.read_csv('E:\\\\data mining\\\\dataset\\\\Reputation-evaluation-of-scenic-spots\\\\fusai\\\\train_second.csv')\n",
    "train = pd.concat([train_first,train_second])\n",
    "test = pd.read_csv('E:\\\\data mining\\\\dataset\\\\Reputation-evaluation-of-scenic-spots\\\\fusai\\\\predict_second.csv')\n",
    "train.columns = ['id', 'discuss', 'score']\n",
    "test.columns = ['id', 'discuss']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stopword = ['【','】','\"','\\'','<','>','的','了','“','”','‘','’',' ']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "patt = re.compile('[\\u4e00-\\u9fa5|,|.|?|!|‘|’|“|”|【|】]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train['discuss'] = train['discuss'].map(lambda x : ''.join(patt.findall(x)))\n",
    "test['discuss'] = test['discuss'].map(lambda x : ''.join(patt.findall(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache C:\\Users\\ADMINI~1.WIN\\AppData\\Local\\Temp\\jieba.cache\n",
      "Loading model cost 1.845 seconds.\n",
      "Prefix dict has been built succesfully.\n"
     ]
    }
   ],
   "source": [
    "train['discuss'] = train['discuss'].map(lambda x : [k for k in jieba.lcut(x) if k not in stopword])\n",
    "test['discuss'] = test['discuss'].map(lambda x :[k for k in jieba.lcut(x) if k not in stopword])\n",
    "all_data = pd.concat([train,test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\gensim\\utils.py:1167: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:7: DeprecationWarning: Call to deprecated `iter` (Attribute will be removed in 4.0.0, use self.epochs instead).\n",
      "  import sys\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(25569103, 29022805)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim.corpora import Dictionary\n",
    "from gensim.models import Word2Vec\n",
    "dic = Dictionary(all_data['discuss'].values)\n",
    "corpus = [dic.doc2bow(x) for x in all_data['discuss'].values]\n",
    "model = Word2Vec(sg=1,size=64,window=4,negative=4)\n",
    "model.build_vocab(all_data['discuss'].values)\n",
    "model.train(all_data['discuss'].values,total_examples=model.corpus_count,epochs=model.iter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:8: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
      "  \n",
      "E:\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py:11: RuntimeWarning: invalid value encountered in true_divide\n",
      "  # This is added back by InteractiveShellApp.init_path()\n"
     ]
    }
   ],
   "source": [
    "w2v = []\n",
    "for line in all_data['discuss'].values:\n",
    "    temp = np.zeros((1,64))\n",
    "    i=0\n",
    "    for w in line:\n",
    "        try:\n",
    "            i+=1\n",
    "            temp+=np.array(model[w])\n",
    "        except Exception:\n",
    "            continue\n",
    "    w2v.append(temp[0]/i)\n",
    "feature=w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5000]\ttraining's rmse: 0.285992\tvalid_1's rmse: 0.623875\n",
      "[10000]\ttraining's rmse: 0.222126\tvalid_1's rmse: 0.621037\n",
      "[15000]\ttraining's rmse: 0.209477\tvalid_1's rmse: 0.621054\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.285756\tvalid_1's rmse: 0.622896\n",
      "[10000]\ttraining's rmse: 0.22318\tvalid_1's rmse: 0.620054\n",
      "[15000]\ttraining's rmse: 0.2103\tvalid_1's rmse: 0.619797\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.285681\tvalid_1's rmse: 0.618507\n",
      "[10000]\ttraining's rmse: 0.222982\tvalid_1's rmse: 0.616073\n",
      "[15000]\ttraining's rmse: 0.210346\tvalid_1's rmse: 0.616019\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.286299\tvalid_1's rmse: 0.617045\n",
      "[10000]\ttraining's rmse: 0.223582\tvalid_1's rmse: 0.614106\n",
      "[15000]\ttraining's rmse: 0.211294\tvalid_1's rmse: 0.613974\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.28542\tvalid_1's rmse: 0.620709\n",
      "[10000]\ttraining's rmse: 0.221378\tvalid_1's rmse: 0.617867\n",
      "[15000]\ttraining's rmse: 0.208682\tvalid_1's rmse: 0.61778\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.286695\tvalid_1's rmse: 0.618406\n",
      "[10000]\ttraining's rmse: 0.22457\tvalid_1's rmse: 0.615378\n",
      "[15000]\ttraining's rmse: 0.211992\tvalid_1's rmse: 0.615229\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.285827\tvalid_1's rmse: 0.618947\n",
      "[10000]\ttraining's rmse: 0.222475\tvalid_1's rmse: 0.615905\n",
      "[15000]\ttraining's rmse: 0.209939\tvalid_1's rmse: 0.615802\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.283794\tvalid_1's rmse: 0.625572\n",
      "[10000]\ttraining's rmse: 0.220886\tvalid_1's rmse: 0.622824\n",
      "[15000]\ttraining's rmse: 0.208399\tvalid_1's rmse: 0.622732\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.284694\tvalid_1's rmse: 0.619517\n",
      "[10000]\ttraining's rmse: 0.222545\tvalid_1's rmse: 0.61695\n",
      "[15000]\ttraining's rmse: 0.210311\tvalid_1's rmse: 0.616865\n",
      "finish one\n",
      "[5000]\ttraining's rmse: 0.284957\tvalid_1's rmse: 0.620936\n",
      "[10000]\ttraining's rmse: 0.221832\tvalid_1's rmse: 0.61819\n",
      "[15000]\ttraining's rmse: 0.209764\tvalid_1's rmse: 0.618077\n",
      "finish one\n"
     ]
    }
   ],
   "source": [
    "score = train.score.values\n",
    "from sklearn.model_selection import train_test_split\n",
    "import lightgbm as lgb\n",
    "test_real_list = []\n",
    "seeds = [2016,2017,2018,2019,2020,2021,20222,2023,2024,2025]\n",
    "test_csr = feature[len(train):]\n",
    "for seed in seeds:\n",
    "    X_train, X_test, y_train, y_test = train_test_split(feature[:len(train)], score, test_size=0.2,random_state=seed)\n",
    "    d_train = lgb.Dataset(X_train, label=y_train,silent=False)\n",
    "    d_test = lgb.Dataset(X_test,label=y_test,silent=False)\n",
    "    params = {\n",
    "        'application': 'regression',\n",
    "        'num_leaves': 64,\n",
    "        'metric': 'RMSE',\n",
    "        'subsample': 0.7,\n",
    "        'colsample_bytree': 0.7,\n",
    "        'reg_alpha':5,\n",
    "        'reg_lambda':5,\n",
    "        'learning_rate':0.08\n",
    "    }\n",
    "    model = lgb.train(params, train_set=d_train, num_boost_round=15000,verbose_eval=5000,valid_sets=[d_train,d_test])\n",
    "    re_real = model.predict(test_csr)\n",
    "    test_real_list.append(re_real)\n",
    "    print('finish one')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "test_real_avg = np.sum(test_real_list,axis=0)/10\n",
    "test['score'] = test_real_avg\n",
    "test['score'] = test['score'].map(lambda x: 5 if x > 4.7 else x)\n",
    "test[['id','score']].to_csv('new_try.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "len(test_real_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
